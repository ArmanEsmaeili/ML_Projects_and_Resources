{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDIXljsbKixH"
      },
      "outputs": [],
      "source": [
        "# 1\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "data = load_iris(as_frame=True)\n",
        "df = data.frame.copy()\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPea47i8SSxr"
      },
      "outputs": [],
      "source": [
        "# 2\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df['target_encoded'] = le.fit_transform(df['target'])\n",
        "print(\"Mapping:\", dict(zip(le.classes_, le.transform(le.classes_))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CCPjPGRSdd0"
      },
      "outputs": [],
      "source": [
        "# 3\n",
        "X = df[data.feature_names].values      \n",
        "y = df['target_encoded'].values        \n",
        "print(\"X shape:\", X.shape, \"y shape:\", y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STtSdhrOTKyT"
      },
      "outputs": [],
      "source": [
        "# 4\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UG8UJcx0TUtk"
      },
      "outputs": [],
      "source": [
        "# 5\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "C_values = [0.1, 1, 10, 100]\n",
        "kernels = ['linear', 'rbf', 'poly', 'sigmoid']\n",
        "\n",
        "best_score = -np.inf\n",
        "best_params = None\n",
        "scores_table = []  # ذخیره همه نتایج برای بررسی بعدی\n",
        "\n",
        "for kernel in kernels:\n",
        "    for C in C_values:\n",
        "        fold_accuracies = []\n",
        "        for train_idx, test_idx in kf.split(X):\n",
        "            X_train, X_test = X[train_idx], X[test_idx]\n",
        "            y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "            model = SVC(C=C, kernel=kernel, probability=False) \n",
        "            model.fit(X_train, y_train)\n",
        "            acc = model.score(X_test, y_test)\n",
        "            fold_accuracies.append(acc)\n",
        "\n",
        "        mean_acc = np.mean(fold_accuracies)\n",
        "        scores_table.append({'kernel': kernel, 'C': C, 'mean_acc': mean_acc})\n",
        "        print(f\"kernel={kernel:<6} C={C:<6} Mean Accuracy={mean_acc:.4f}\")\n",
        "\n",
        "        if mean_acc > best_score:\n",
        "            best_score = mean_acc\n",
        "            best_params = {'kernel': kernel, 'C': C}\n",
        "\n",
        "print(\"\\nBest params:\", best_params, \"with mean accuracy:\", best_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0X8tPC7jV7GW"
      },
      "outputs": [],
      "source": [
        "# 6\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0, stratify=y)\n",
        "\n",
        "best_model = SVC(C=best_params['C'], kernel=best_params['kernel'], probability=False)\n",
        "best_model.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lecqSxj2WBuT"
      },
      "outputs": [],
      "source": [
        "# 7\n",
        "sorted_scores = sorted(scores_table, key=lambda x: x['mean_acc'])\n",
        "worst = sorted_scores[0]\n",
        "print(\"Worst params (non-optimal):\", worst)\n",
        "\n",
        "bad_model = SVC(C=worst['C'], kernel=worst['kernel'], probability=False)\n",
        "bad_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb8EAdF_WGVN"
      },
      "outputs": [],
      "source": [
        "# 8\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# پیش‌بینی‌ها\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "y_pred_bad  = bad_model.predict(X_test)\n",
        "\n",
        "# معیارهای عددی\n",
        "print(\"=== Best model metrics ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_best))\n",
        "print(classification_report(y_test, y_pred_best))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_best))\n",
        "\n",
        "print(\"\\n=== Bad model metrics ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_bad))\n",
        "print(classification_report(y_test, y_pred_bad))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_bad))\n",
        "\n",
        "y_test_bin = label_binarize(y_test, classes=np.unique(y))\n",
        "n_classes = y_test_bin.shape[1]\n",
        "\n",
        "# برای مدل بهینه\n",
        "ovr_best = OneVsRestClassifier(best_model)\n",
        "y_score_best = ovr_best.fit(X_train, y_train).decision_function(X_test)\n",
        "\n",
        "# برای مدل بد\n",
        "ovr_bad = OneVsRestClassifier(bad_model)\n",
        "y_score_bad = ovr_bad.fit(X_train, y_train).decision_function(X_test)\n",
        "\n",
        "# رسم ROC برای هر کلاس و محاسبه AUC\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "for i in range(n_classes):\n",
        "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score_best[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, lw=2, label=f'class {i} (AUC={roc_auc:.2f})')\n",
        "plt.title('ROC - Best model')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "for i in range(n_classes):\n",
        "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score_bad[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, lw=2, label=f'class {i} (AUC={roc_auc:.2f})')\n",
        "plt.title('ROC - Bad model')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# خلاصه مقایسه\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "def summarize(y_true, y_pred):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
        "    return {'accuracy': acc, 'precision_macro': precision, 'recall_macro': recall, 'f1_macro': f1}\n",
        "\n",
        "print(\"Summary - Best model:\", summarize(y_test, y_pred_best))\n",
        "print(\"Summary - Bad model:\", summarize(y_test, y_pred_bad))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
